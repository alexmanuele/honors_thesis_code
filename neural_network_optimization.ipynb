{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from keras.layers import Lambda, Input, Dense, MaxPooling1D, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras import utils\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras import objectives\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import itertools as it\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_expansion(x_data,y, magnitude, sigma, k):\n",
    "    mu = 0.0\n",
    "    num_samples = x_data.shape[0]\n",
    "    x_noised = []\n",
    "    for i in range(magnitude):\n",
    "        noise = np.random.normal(mu, sigma, x_data.shape)\n",
    "        x_noised.append(x_data + noise)\n",
    "        \n",
    "    y_new = [y] * (magnitude +1)\n",
    "    y_new = np.asarray(y_new).flatten()\n",
    "    print(y_new.shape)\n",
    "    x_noised = np.asarray(x_noised)\n",
    "    x_noised = x_noised.reshape(magnitude*x_data.shape[0],k,1)\n",
    "    print(x_noised.shape)\n",
    "    print(x_data.shape)\n",
    "    y_new = enc.transform(np.reshape(y_new, (-1,1)))\n",
    "    new_x = np.concatenate((x_data, x_noised))\n",
    "    \n",
    "    print(y_new.shape)\n",
    "    print(new_x.shape)\n",
    "    return(new_x, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(k):\n",
    "    inputs = layers.Input(shape=(k,1,))\n",
    "    x = layers.Conv1D(32, 2)(inputs)\n",
    "    x = layers.MaxPooling1D()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(30, activation='relu')(x)\n",
    "    outputs = layers.Dense(2,activation='softmax')(x)\n",
    "    fancy_model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    fancy_model.summary()\n",
    "    fancy_model.compile(loss='binary_crossentropy',\n",
    "                   optimizer='Adam', metrics=['accuracy'])\n",
    "    return fancy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 1998)\n",
      "(105, 1998)\n"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv('all_subg_samples.csv', index_col=0).values\n",
    "sup = pd.read_csv('all_supg_samples.csv', index_col=0).values\n",
    "\n",
    "print(sub.shape)\n",
    "print(sup.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cnn(X, y, n_folds, sigma, noise_size, k, enc):\n",
    "    skf = StratifiedKFold(n_splits=n_folds)\n",
    "    scores = []\n",
    "    for train, test in skf.split(X_new, y):\n",
    "        X_train, X_test = X_new[train], X_new[test]\n",
    "        y_train, y_test = y[train], y[test]\n",
    "        y_test = enc.transform(np.reshape(y_test, (-1,1)))\n",
    "        x_tr, y_tr = gaussian_expansion(X_train, y_train,noise_size, sigma,k)\n",
    "        model = create_model(k)\n",
    "        model.fit(x_tr, y_tr, batch_size=6, epochs=30, validation_data=(X_test, y_test), \n",
    "                  callbacks=[EarlyStopping('val_loss', patience=4, restore_best_weights=True)])\n",
    "        clear_output()\n",
    "        evals = model.evaluate(X_test, y_test)\n",
    "        scores.append(evals[1])\n",
    "    return {'Params':{'noise_sigma': sigma, 'noise_size':noise_size, 'k_best':k}, \n",
    "            'Result':{'mean_acc':np.mean(scores), 'mean_std':np.std(scores)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_sigma = [0.0, 0.01, 0.005]\n",
    "noise_size = [10, 25, 40]\n",
    "gen = it.product(noise_sigma, noise_size)\n",
    "\n",
    "\n",
    "noise_params = []\n",
    "for i in gen:\n",
    "    noise_params.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((sub, sup))\n",
    "\n",
    "y = [0] * 105 + [1] * 105\n",
    "y = np.asarray(y)\n",
    "\n",
    "X_new = SelectKBest(mutual_info_classif, k=200).fit_transform(X, y)\n",
    "X_new = np.reshape(X_new, (210,200,1))\n",
    "\n",
    "\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "labels = np.arange(2)\n",
    "labels = np.reshape(labels, (len(labels),1))\n",
    "enc.fit(labels)\n",
    "\n",
    "results = []\n",
    "\n",
    "for params in noise_params:\n",
    "    results.append(kfold_cnn(X_new, y, 15, params[0], params[1], 200, enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Params': {'noise_sigma': 0.0, 'noise_size': 10, 'k_best': 200},\n",
       "  'Result': {'mean_acc': 0.6238095303376515, 'mean_std': 0.10900497954220405}},\n",
       " {'Params': {'noise_sigma': 0.0, 'noise_size': 25, 'k_best': 200},\n",
       "  'Result': {'mean_acc': 0.6666666666666666, 'mean_std': 0.13468699510253443}},\n",
       " {'Params': {'noise_sigma': 0.0, 'noise_size': 40, 'k_best': 200},\n",
       "  'Result': {'mean_acc': 0.6476190487543741, 'mean_std': 0.1341809802504021}},\n",
       " {'Params': {'noise_sigma': 0.01, 'noise_size': 10, 'k_best': 200},\n",
       "  'Result': {'mean_acc': 0.680952384074529, 'mean_std': 0.09712418019542482}},\n",
       " {'Params': {'noise_sigma': 0.01, 'noise_size': 25, 'k_best': 200},\n",
       "  'Result': {'mean_acc': 0.6857142905394237, 'mean_std': 0.09689042724229598}},\n",
       " {'Params': {'noise_sigma': 0.01, 'noise_size': 40, 'k_best': 200},\n",
       "  'Result': {'mean_acc': 0.6619047681490581, 'mean_std': 0.10900498605180613}},\n",
       " {'Params': {'noise_sigma': 0.005, 'noise_size': 10, 'k_best': 200},\n",
       "  'Result': {'mean_acc': 0.6523809572060902, 'mean_std': 0.11625290866120881}},\n",
       " {'Params': {'noise_sigma': 0.005, 'noise_size': 25, 'k_best': 200},\n",
       "  'Result': {'mean_acc': 0.6857142885526021, 'mean_std': 0.106904491454967}},\n",
       " {'Params': {'noise_sigma': 0.005, 'noise_size': 40, 'k_best': 200},\n",
       "  'Result': {'mean_acc': 0.6857142925262452, 'mean_std': 0.1160576865337094}}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Params': {'noise_sigma': 0.0, 'noise_size': 10, 'k_best': 100},\n",
       "  'Result': {'mean_acc': 0.8875, 'mean_std': 0.1849831073368593}},\n",
       " {'Params': {'noise_sigma': 0.0, 'noise_size': 25, 'k_best': 100},\n",
       "  'Result': {'mean_acc': 0.9125, 'mean_std': 0.16345871038277526}},\n",
       " {'Params': {'noise_sigma': 0.0, 'noise_size': 40, 'k_best': 100},\n",
       "  'Result': {'mean_acc': 0.8875, 'mean_std': 0.1849831073368593}},\n",
       " {'Params': {'noise_sigma': 0.0, 'noise_size': 100, 'k_best': 100},\n",
       "  'Result': {'mean_acc': 0.8875, 'mean_std': 0.20116846174288852}},\n",
       " {'Params': {'noise_sigma': 0.1, 'noise_size': 10, 'k_best': 100},\n",
       "  'Result': {'mean_acc': 0.675, 'mean_std': 0.225}},\n",
       " {'Params': {'noise_sigma': 0.1, 'noise_size': 25, 'k_best': 100},\n",
       "  'Result': {'mean_acc': 0.625, 'mean_std': 0.20155644370746376}},\n",
       " {'Params': {'noise_sigma': 0.1, 'noise_size': 40, 'k_best': 100},\n",
       "  'Result': {'mean_acc': 0.6625, 'mean_std': 0.21323402636539976}},\n",
       " {'Params': {'noise_sigma': 0.1, 'noise_size': 100, 'k_best': 100},\n",
       "  'Result': {'mean_acc': 0.675, 'mean_std': 0.225}},\n",
       " {'Params': {'noise_sigma': 0.01, 'noise_size': 10, 'k_best': 100},\n",
       "  'Result': {'mean_acc': 0.875, 'mean_std': 0.16770509831248423}},\n",
       " {'Params': {'noise_sigma': 0.01, 'noise_size': 25, 'k_best': 100},\n",
       "  'Result': {'mean_acc': 0.9125, 'mean_std': 0.16345871038277526}},\n",
       " {'Params': {'noise_sigma': 0.01, 'noise_size': 40, 'k_best': 100},\n",
       "  'Result': {'mean_acc': 0.9, 'mean_std': 0.16583123951777}},\n",
       " {'Params': {'noise_sigma': 0.01, 'noise_size': 100, 'k_best': 100},\n",
       "  'Result': {'mean_acc': 0.9, 'mean_std': 0.16583123951777}},\n",
       " {'Params': {'noise_sigma': 0.005, 'noise_size': 10, 'k_best': 100},\n",
       "  'Result': {'mean_acc': 0.9125, 'mean_std': 0.143069039278245}},\n",
       " {'Params': {'noise_sigma': 0.005, 'noise_size': 25, 'k_best': 100},\n",
       "  'Result': {'mean_acc': 0.9375, 'mean_std': 0.15562374497485915}},\n",
       " {'Params': {'noise_sigma': 0.005, 'noise_size': 40, 'k_best': 100},\n",
       "  'Result': {'mean_acc': 0.9, 'mean_std': 0.16583123951777}},\n",
       " {'Params': {'noise_sigma': 0.005, 'noise_size': 100, 'k_best': 100},\n",
       "  'Result': {'mean_acc': 0.925, 'mean_std': 0.16007810593582122}},\n",
       " {'Params': {'noise_sigma': 0.001, 'noise_size': 10, 'k_best': 100},\n",
       "  'Result': {'mean_acc': 0.925, 'mean_std': 0.13919410907075053}},\n",
       " {'Params': {'noise_sigma': 0.001, 'noise_size': 25, 'k_best': 100},\n",
       "  'Result': {'mean_acc': 0.9125, 'mean_std': 0.16345871038277526}},\n",
       " {'Params': {'noise_sigma': 0.001, 'noise_size': 40, 'k_best': 100},\n",
       "  'Result': {'mean_acc': 0.9, 'mean_std': 0.18371173070873836}},\n",
       " {'Params': {'noise_sigma': 0.001, 'noise_size': 100, 'k_best': 100},\n",
       "  'Result': {'mean_acc': 0.9, 'mean_std': 0.18371173070873836}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(data):\n",
    "    rows=data.index\n",
    "    indices = []\n",
    "    for p in range(11,26):\n",
    "        train = []\n",
    "        test = []\n",
    "        sample = \"{0}\".format(p)\n",
    "        for i in range(len(rows)):   \n",
    "            if sample in rows[i]:\n",
    "                test.append(i)\n",
    "            else:\n",
    "                train.append(i)\n",
    "        indices.append((train, test))\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass X as a dataframe here\n",
    "def kfold_partitioned_cnn(X, y, sigma, noise_size, k, enc):\n",
    "    train_test_split = partition(X)\n",
    "    scores = []\n",
    "    for split in train_test_split:\n",
    "        X_train, X_test = X.values[split[0]], X.values[split[1]]\n",
    "        X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "        X_test = X_test.reshape(X_test.shape[0], X_test.shape[1],1)\n",
    "        y_train, y_test = y[split[0]], y[split[1]]\n",
    "        y_test = enc.transform(np.reshape(y_test, (-1,1)))\n",
    "        x_tr, y_tr = gaussian_expansion(X_train, y_train,noise_size, sigma,k)\n",
    "        model = create_model(k)\n",
    "        model.fit(x_tr, y_tr, batch_size=6, epochs=10, validation_data=(X_test, y_test), \n",
    "                  callbacks=[EarlyStopping('val_loss', patience=4, restore_best_weights=True)])\n",
    "        clear_output()\n",
    "        evals = model.evaluate(X_test, y_test)\n",
    "        scores.append(evals[1])\n",
    "    return {'Params':{'noise_sigma': sigma, 'noise_size':noise_size, 'k_best':k}, \n",
    "            'Result':{'mean_acc':np.mean(scores), 'mean_std':np.std(scores)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sub_best.csv', index_col=0)\n",
    "sup = pd.read_csv('sup_best.csv', index_col=0)\n",
    "\n",
    "noise_sigma = [0.0, 0.01, 0.005]\n",
    "noise_size = [10, 25, 40]\n",
    "gen = it.product(noise_sigma, noise_size)\n",
    "\n",
    "\n",
    "noise_params = []\n",
    "for i in gen:\n",
    "    noise_params.append(i)\n",
    "X = sub.append(sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sub_best.csv', index_col=0)\n",
    "sup = pd.read_csv('sup_best.csv', index_col=0)\n",
    "data = sub.append(sup)\n",
    "\n",
    "data_index = data.index\n",
    "\n",
    "X_vals = data.values\n",
    "\n",
    "X_new = SelectKBest(mutual_info_classif, k=200).fit_transform(X_vals, y)\n",
    "\n",
    "X = pd.DataFrame(data=X_new, index=data_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "results2 = []\n",
    "for params in noise_params:\n",
    "    results2.append(kfold_partitioned_cnn(X, y, params[0], params[1], 200, enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Params': {'noise_sigma': 0.0, 'noise_size': 10, 'k_best': 200},\n",
       "  'Result': {'mean_acc': 0.8979166666666667, 'mean_std': 0.14722549786712294}},\n",
       " {'Params': {'noise_sigma': 0.0, 'noise_size': 25, 'k_best': 200},\n",
       "  'Result': {'mean_acc': 0.9166666666666666, 'mean_std': 0.11102427162061856}},\n",
       " {'Params': {'noise_sigma': 0.0, 'noise_size': 40, 'k_best': 200},\n",
       "  'Result': {'mean_acc': 0.88125, 'mean_std': 0.1746275799141323}},\n",
       " {'Params': {'noise_sigma': 0.01, 'noise_size': 10, 'k_best': 200},\n",
       "  'Result': {'mean_acc': 0.8916666666666667, 'mean_std': 0.1259684704819248}},\n",
       " {'Params': {'noise_sigma': 0.01, 'noise_size': 25, 'k_best': 200},\n",
       "  'Result': {'mean_acc': 0.9333333333333333, 'mean_std': 0.10324593077803224}},\n",
       " {'Params': {'noise_sigma': 0.01, 'noise_size': 40, 'k_best': 200},\n",
       "  'Result': {'mean_acc': 0.925, 'mean_std': 0.10813282726967482}},\n",
       " {'Params': {'noise_sigma': 0.005, 'noise_size': 10, 'k_best': 200},\n",
       "  'Result': {'mean_acc': 0.9104166666666667, 'mean_std': 0.11906026718524622}},\n",
       " {'Params': {'noise_sigma': 0.005, 'noise_size': 25, 'k_best': 200},\n",
       "  'Result': {'mean_acc': 0.91875, 'mean_std': 0.10933034802834941}},\n",
       " {'Params': {'noise_sigma': 0.005, 'noise_size': 40, 'k_best': 200},\n",
       "  'Result': {'mean_acc': 0.9166666666666666, 'mean_std': 0.10925092168439078}}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "0.75\n",
      "0.75\n",
      "0.75\n",
      "0.75\n",
      "1.0\n",
      "0.75\n",
      "1.0\n",
      "0.75\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.5\n",
      "0.9   0.14577379737113252\n"
     ]
    }
   ],
   "source": [
    "for i in scores:\n",
    "    print(i)\n",
    "print(np.mean(scores), \" \", np.std(scores)) #no noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "1.0\n",
      "1.0\n",
      "0.75\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.75\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.5\n",
      "1.0\n",
      "1.0\n",
      "0.9375   0.1340475661845451\n"
     ]
    }
   ],
   "source": [
    "for i in scores:\n",
    "    print(i)\n",
    "print(np.mean(scores), \" \", np.std(scores))\n",
    "#params: 40fold noise generation with std=0.001\n",
    "#20 fold cv with batch size 6, epochs=10, patience=4, early stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "1.0\n",
      "1.0\n",
      "0.5\n",
      "0.5\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.75\n",
      "1.0\n",
      "0.5\n",
      "1.0\n",
      "0.5\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.875   0.20155644370746376\n"
     ]
    }
   ],
   "source": [
    "for i in scores:\n",
    "    print(i)\n",
    "print(np.mean(scores), \" \", np.std(scores)) #sigma = 0.005 for noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
